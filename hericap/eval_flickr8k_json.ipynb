{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c413c986-9951-48b2-9bbc-4f26bbc486e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " json file is saved in /gemini/output/flickr8k_test.json .\n"
     ]
    }
   ],
   "source": [
    "# 1.  Firstly, convert the initial json file to standard MS-COCO format \n",
    "#  dataset_flickr8k.json   ---->    flickr8k_test.json / flickr8k_val.json  \n",
    " \n",
    "import json\n",
    "import os\n",
    "\n",
    "def read_input_file(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return json.load(f)\n",
    " \n",
    "def write_output_file(file_path, data):\n",
    "    output_dir = os.path.dirname(file_path)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "def convert_json(input_data, split, dataset_name):\n",
    "\n",
    "    output_data = {\n",
    "        \"licenses\": [],\n",
    "        \"info\": {\n",
    "            \"url\": \"\",\n",
    "            \"date_created\": \" \",\n",
    "            \"version\": \"0.1\",\n",
    "            \"description\": f\"{dataset_name} {split} dataset\",\n",
    "            \"contributor\": \"\",\n",
    "            \"year\": \"\"\n",
    "        },\n",
    "        \"images\": [],\n",
    "        \"annotations\": [],\n",
    "        \"type\": \"captions\"\n",
    "    }\n",
    "\n",
    "    for image in input_data[\"images\"]:\n",
    "\n",
    "        if image[\"split\"] == split:\n",
    "\n",
    "            output_data[\"images\"].append({\n",
    "                \"file_name\": image[\"filename\"],\n",
    "                \"fkickr_id\": image[\"filename\"].split(\".\")[0],  \n",
    "                \"id\": image[\"imgid\"],\n",
    "            })\n",
    "            \n",
    "            for sentence in image[\"sentences\"]:\n",
    "                output_data[\"annotations\"].append({\n",
    "                    \"image_id\": image[\"imgid\"],\n",
    "                    \"id\": sentence[\"sentid\"],\n",
    "                    \"caption\": sentence[\"raw\"]\n",
    "                })\n",
    "    return output_data\n",
    "\n",
    "\n",
    "def main(input_file_path, output_file_path, split, dataset_name):\n",
    "\n",
    "    input_data = read_input_file(input_file_path)\n",
    "    output_data = convert_json(input_data, split, dataset_name)\n",
    "    write_output_file(output_file_path, output_data)\n",
    "    print(f\" json file is saved in {output_file_path} .\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_name =  \"flickr8k\" # flickr30k   flickr8k\n",
    "    split = \"test\"  #  \"train\" \"test\" \"val\"\n",
    "    input_file_path = f\"/gemini/data-2/caption_datasets/dataset_{dataset_name}.json\" \n",
    "    output_file_path = f\"/gemini/output/{dataset_name}_{split}.json\"  \n",
    "    \n",
    "    main(input_file_path, output_file_path, split, dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef14a0e3-cf69-49c1-862e-33289c027416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.   run the eval_flickr8k.py script to obtain the flickr8k_test_result.json.\n",
    "\n",
    "# run as bash command\n",
    "export DATA_ROOT=${GEMINI_DATA_IN2}/flickr8k_images           \n",
    "export OUTPUT_ROOT=${GEMINI_DATA_OUT}\n",
    "export MODEL_ROOT1=${GEMINI_PRETRAIN}\n",
    "export MODEL_ROOT2=${GEMINI_PRETRAIN2}    \n",
    "python eval_flickr8k.py ++model.cap_generator.decoder_name=Parallel \\\n",
    "    exp.checkpoint=${MODEL_ROOT2}/checkpoint_best_test.pth \\\n",
    "    exp.name=flickr8k_evaluation_Parallel \\\n",
    "    optimizer.num_workers=2 \\\n",
    "    exp.ngpus_per_node=2 \\\n",
    "    exp.world_size=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddf07621-9efd-48c8-9316-3be291834659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PTBTokenizer tokenized 64178 tokens at 267971.51 tokens per second.\n",
      "PTBTokenizer tokenized 10264 tokens at 128472.14 tokens per second.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 9265, 'reflen': 9256, 'guess': [9265, 8265, 7265, 6265], 'correct': [6790, 3432, 1453, 579]}\n",
      "ratio: 1.0009723422643688\n",
      "Bleu_1: 0.733\n",
      "Bleu_2: 0.552\n",
      "Bleu_3: 0.393\n",
      "Bleu_4: 0.274\n",
      "computing METEOR score...\n",
      "METEOR: 0.251\n",
      "computing Rouge score...\n",
      "ROUGE_L: 0.536\n",
      "computing CIDEr score...\n",
      "CIDEr: 0.785\n",
      "computing SPICE score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.nustaq.serialization.FSTClazzInfo (file:/root/miniconda3/lib/python3.9/site-packages/pycocoevalcap/spice/lib/fst-2.47.jar) to field java.lang.String.value\n",
      "WARNING: Please consider reporting this to the maintainers of org.nustaq.serialization.FSTClazzInfo\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Parsing reference captions\n",
      "Initiating Stanford parsing pipeline\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator tokenize\n",
      "[main] INFO edu.stanford.nlp.pipeline.TokenizerAnnotator - TokenizerAnnotator: No tokenizer type provided. Defaulting to PTBTokenizer.\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ssplit\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator parse\n",
      "[main] INFO edu.stanford.nlp.parser.common.ParserGrammar - Loading parser from serialized file edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz ... \n",
      "done [0.4 sec].\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator lemma\n",
      "[main] INFO edu.stanford.nlp.pipeline.StanfordCoreNLP - Adding annotator ner\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.all.3class.distsim.crf.ser.gz ... done [1.1 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.muc.7class.distsim.crf.ser.gz ... done [0.5 sec].\n",
      "Loading classifier from edu/stanford/nlp/models/ner/english.conll.4class.distsim.crf.ser.gz ... done [0.7 sec].\n",
      "Threads( StanfordCoreNLP ) [24.689 seconds]\n",
      "Parsing test captions\n",
      "Threads( StanfordCoreNLP ) [3.31 seconds]\n",
      "Warning: Nashorn engine is planned to be removed from a future JDK release\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPICE evaluation took: 35.92 s\n",
      "SPICE: 0.190\n",
      "Bleu_1: 0.733\n",
      "Bleu_2: 0.552\n",
      "Bleu_3: 0.393\n",
      "Bleu_4: 0.274\n",
      "METEOR: 0.251\n",
      "ROUGE_L: 0.536\n",
      "CIDEr: 0.785\n",
      "SPICE: 0.190\n"
     ]
    }
   ],
   "source": [
    "#3.  evalution the flickr8k_test_result.json by eval_json_by_pycocoevalcap.py\n",
    "\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "from pycocoevalcap.eval import COCOEvalCap\n",
    "\n",
    "\n",
    "def main(annotation_file=None, results_file=None):\n",
    "\n",
    "    # Downloading stanford-corenlp-3.6.0, and move it to /root/miniconda3/lib/python3.9/site-packages/pycocoevalcap/spice/lib\n",
    "\n",
    "    # create coco object and coco_result object\n",
    "    coco = COCO(annotation_file)\n",
    "    coco_result = coco.loadRes(results_file)\n",
    "\n",
    "    # create coco_eval object by taking coco and coco_result\n",
    "    coco_eval = COCOEvalCap(coco, coco_result)\n",
    "    # evaluate on a subset of images by setting\n",
    "    # coco_eval.params['image_id'] = coco_result.getImgIds()\n",
    "    # please remove this line when evaluating the full validation set\n",
    "    coco_eval.params['image_id'] = coco_result.getImgIds()\n",
    "\n",
    "    # evaluate results\n",
    "    # SPICE will take a few minutes the first time, but speeds up due to caching\n",
    "\n",
    "    coco_eval.evaluate()\n",
    "\n",
    "    # print output evaluation scores\n",
    "    for metric, score in coco_eval.eval.items():\n",
    "        print(f'{metric}: {score:.3f}')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    annotation_file=\"/gemini/output/flickr8k_test.json\"\n",
    "    results_file=\"/gemini/output/flickr8k_evaluation_Parallel/flickr8k_test_result.json\"\n",
    "    main(annotation_file,results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9676cafa-2ce9-492e-8676-2c065e665bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
